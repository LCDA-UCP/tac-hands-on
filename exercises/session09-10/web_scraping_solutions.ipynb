{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction to Web Scraping in Python\n",
    "\n",
    "Web scraping involves extracting and processing data from websites.\n",
    "\n",
    "The web is one of the richest sources of information available today. Fields like data science, business intelligence, and journalism can gain valuable insights by collecting and analyzing web data.\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Extract website data using string manipulation and regular expressions\n",
    "- Parse HTML content with an HTML parser\n",
    "- Interact with forms and dynamic web elements\n",
    "\n",
    "\n"
   ],
   "id": "dd0745f53f218a78"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Before using Python for web scraping, always review the website's terms of service to ensure automated access is allowed. Scraping a website without permission can be legally unclear, and violating its terms may lead to potential issues.**",
   "id": "94dbcba63286c8ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "9087d0a69b913560"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Building Our First Web Scraper\n",
    "\n",
    "A useful package for web scraping in Python’s standard library is `urllib`, which provides tools for handling URLs. Specifically, the `urllib.request` module includes the `urlopen()` function, allowing you to open a URL directly within your program.\n"
   ],
   "id": "3a33d317d9cf3574"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For this tutorial, we’ll use a page that’s hosted on Real Python’s server. The page that we’ll access has been set up for use with these kind of tutorials.",
   "id": "b502640d0e7def95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. - Using ```urllib``` ",
   "id": "f4a21802551516b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 - Import the `urlopen` Function from the `urllib.request` Module",
   "id": "8b6ce76c8f0df69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:30:47.121277Z",
     "start_time": "2024-10-17T14:30:47.119201Z"
    }
   },
   "cell_type": "code",
   "source": "from urllib.request import urlopen",
   "id": "535e0225fa4db892",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 - Define the URL to Scrape",
   "id": "6dd87cb8befe33c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:30:48.032476Z",
     "start_time": "2024-10-17T14:30:48.029849Z"
    }
   },
   "cell_type": "code",
   "source": "url = \"http://olympus.realpython.org/profiles/aphrodite\"",
   "id": "21ccb6a6bc72bb79",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3 - Open a URL Using `urlopen()`",
   "id": "786ed0b1c7332fb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:30:49.290799Z",
     "start_time": "2024-10-17T14:30:49.000025Z"
    }
   },
   "cell_type": "code",
   "source": "page = urlopen(url)",
   "id": "69c2d49727d4d5d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:30:49.818494Z",
     "start_time": "2024-10-17T14:30:49.815061Z"
    }
   },
   "cell_type": "code",
   "source": "page # urlopen() returns an HTTPResponse object",
   "id": "6d652046a6be82c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x7b13575252d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.4 - Extract the HTML Content of the Page\n",
    "\n",
    "TTo extract the HTML from a webpage, first use the `.read()` method of the `HTTPResponse` object, which returns the data as a sequence of bytes. Then, apply the `.decode()` method to convert the bytes into a string, typically using UTF-8 encoding.\n"
   ],
   "id": "3a656c439f563efd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:30:50.871553Z",
     "start_time": "2024-10-17T14:30:50.869224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "html_bytes = page.read()\n",
    "html = html_bytes.decode(\"utf-8\")"
   ],
   "id": "4e76725b105a7fb7",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:30:51.829802Z",
     "start_time": "2024-10-17T14:30:51.827208Z"
    }
   },
   "cell_type": "code",
   "source": "print(html)",
   "id": "bc5d5281cc98e5d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Profile: Aphrodite</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/aphrodite.gif\" />\n",
      "<h2>Name: Aphrodite</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dove\n",
      "<br><br>\n",
      "Favorite color: Red\n",
      "<br><br>\n",
      "Hometown: Mount Olympus\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The output you're viewing is the HTML code of the website, which your browser interprets and renders when you visit [http://olympus.realpython.org/profiles/aphrodite](http://olympus.realpython.org/profiles/aphrodite).\n",
    "\n",
    "Using `urllib`, you accessed the website just like a browser would. However, instead of displaying the content visually, you retrieved the source code as text. Now that you have the HTML as text, you can extract information from it in several ways.\n",
    "\n"
   ],
   "id": "2063008f4a6a126f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "6c2a6091859278a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. - Extract Text From HTML With String Methods",
   "id": "a3bb49d6f050bd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "One way to extract information from a webpage's HTML is by using string methods. For example, you can use `.find()` to search through the HTML text for the `<title>` tags and extract the page's title.\n",
    "\n",
    "To begin, you'll extract the title from the webpage you requested earlier. If you know the index of the first character of the title and the index of the closing `</title>` tag, you can use a string slice to retrieve the title.\n",
    "\n",
    "Since `.find()` returns the index of the first occurrence of a substring, you can get the index of the opening `<title>` tag by passing the string `\"<title>\"` to `.find()`:\n"
   ],
   "id": "f70bb8d7f099879f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 - Extract the Title of the Page",
   "id": "8185335f09d44d77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:39:12.100233Z",
     "start_time": "2024-10-17T14:39:12.096792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_index = html.find(\"<title>\")\n",
    "title_index"
   ],
   "id": "47ef6265dd5ce906",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You don't actually want the index of the `<title>` tag itself, but rather the index of the title text. To get the index of the first letter in the title, simply add the length of the string `\"<title>\"` to the `title_index` value:\n",
   "id": "2dff76a24bdf683f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:16.127316Z",
     "start_time": "2024-10-15T15:01:16.123621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_index = title_index + len(\"<title>\")\n",
    "start_index"
   ],
   "id": "fcdd7afb0e7c1cd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, get the index of the closing `</title>` tag by passing the string `\"</title>\"` to `.find()`:\n",
   "id": "f5f2ed76ebf077e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:16.183857Z",
     "start_time": "2024-10-15T15:01:16.180161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "end_index = html.find(\"</title>\")\n",
    "end_index"
   ],
   "id": "34425e1ab61c61bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, you can extract the title by slicing the HTML string:",
   "id": "37a116f579ca618"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:16.256081Z",
     "start_time": "2024-10-15T15:01:16.252012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title = html[start_index:end_index]\n",
    "title"
   ],
   "id": "ee07accbc60f67b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Profile: Aphrodite'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Real-world HTML can be much more complex and unpredictable compared to the HTML on the Aphrodite profile page. Here’s [another profile page](http://olympus.realpython.org/profiles/poseidon) with messier HTML that you can scrape:\n",
   "id": "70ad4c083ef91019"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:59:47.797971Z",
     "start_time": "2024-10-17T14:59:47.795902Z"
    }
   },
   "cell_type": "code",
   "source": "url = \"http://olympus.realpython.org/profiles/poseidon\"",
   "id": "406c2b8ac3b3a737",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T14:59:49.689164Z",
     "start_time": "2024-10-17T14:59:49.344760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "print(html)"
   ],
   "id": "9bd0762a915c7b13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title >Profile: Poseidon</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/poseidon.jpg\" />\n",
      "<h2>Name: Poseidon</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dolphin\n",
      "<br><br>\n",
      "Favorite color: Blue\n",
      "<br><br>\n",
      "Hometown: Sea\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 - Extract the Title of the New Page",
   "id": "3d4deb25be1931b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T15:06:26.521003Z",
     "start_time": "2024-10-17T15:06:26.189677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"http://olympus.realpython.org/profiles/poseidon\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "start_index = html.find(\"<title>\") + len(\"<title>\")\n",
    "end_index = html.find(\"</title>\")\n",
    "title = html[start_index:end_index]\n",
    "title"
   ],
   "id": "89e397c1fa523fc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<head>\\n<title >Profile: Poseidon'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Whoops! There’s a bit of HTML mixed in with the title. Why is that?\n",
    "\n",
    "The HTML for the `/profiles/poseidon` page looks similar to the `/profiles/aphrodite` page, but there’s a small difference: the opening `<title>` tag has an extra space before the closing angle bracket (>), rendering it as `<title >`.\n",
    "\n",
    "As a result, `html.find(\"<title>\")` returns -1 because the exact substring `\"<title>\"` doesn’t exist. When -1 is added to `len(\"<title>\")`, which is 7, the `start_index` variable is assigned the value 6.\n",
    "\n",
    "The character at index 6 of the `html` string is a newline character (`\\n`), right before the opening angle bracket (<) of the `<head>` tag. This means that `html[start_index:end_index]` returns all the HTML starting from that newline and ending just before the `</title>` tag.\n",
    "\n",
    "These types of issues can arise in many unpredictable ways, highlighting the need for a more reliable method to extract text from HTML.\n"
   ],
   "id": "f0557f55b699e2d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "d0ae3167dfac58d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. - Extract Text From HTML With Regular Expressions\n",
    "\n",
    "Regular expressions—or regexes for short—are patterns used to search for text within a string. Python supports regular expressions through the standard library's `re` module.\n"
   ],
   "id": "c1942a086ce96a8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 - Import the `re` Module",
   "id": "b46c9792ae1d1a63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T15:09:57.001023Z",
     "start_time": "2024-10-17T15:09:56.998845Z"
    }
   },
   "cell_type": "code",
   "source": "import re",
   "id": "f50872da7683c7d1",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2 - Try to parse out the title [from another profile page](http://olympus.realpython.org/profiles/dionysus), which contains this rather carelessly written line of HTML:\n",
    "\n",
    "```html\n",
    "<TITLE >Profile: Dionysus</title  / >\n",
    "```"
   ],
   "id": "ae538dae049a5d3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T15:28:19.933489Z",
     "start_time": "2024-10-17T15:28:19.566402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "\n",
    "pattern = \"<title.*?>.*?</title.*?>\"\n",
    "match_results = re.search(pattern, html, re.IGNORECASE)\n",
    "title = match_results.group()\n",
    "title = re.sub(\"<.*?>\", \"\", title) # Remove HTML tags\n",
    "\n",
    "print(title)"
   ],
   "id": "aea30f81514ef1ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: Dionysus\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's break down the first regular expression in the pattern string into three components:\n",
    "\n",
    "1. `<title.*?>` matches the opening `<TITLE>` tag in the HTML. The `<title` portion aligns with `<TITLE` because `re.search()` is invoked with `re.IGNORECASE`. The `.*?>` portion matches any text that follows `<TITLE` up to the first occurrence of `>`.\n",
    "\n",
    "2. `.*?` matches all text following the opening `<TITLE>`, but does so non-greedily, meaning it stops at the first instance of `</title.*?>`.\n",
    "\n",
    "3. `</title.*?>` is similar to the first pattern, but it includes the `/` character, allowing it to match the closing `</title>` tag in the HTML.\n",
    "\n",
    "The second regular expression, `<.*?>`, also employs the non-greedy `.*?` to match all HTML tags within the title string. By replacing any found matches with `\"\"`, the `re.sub()` function effectively removes all tags, leaving only the text.\n",
    "\n"
   ],
   "id": "2351aff03480bd2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "e4069a696c1bf89f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. - Check Your Understanding",
   "id": "f8a46405bb98c5a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Write a program that grabs the full HTML from the following URL:\n",
    "\n",
    "### [http://olympus.realpython.org/profiles/dionysus](http://olympus.realpython.org/profiles/dionysus)\n",
    "\n",
    "### Next, use `.find()` to extract the text following \"Name:\" and \"Favorite Color:\". Ensure that you do not include any leading spaces or trailing HTML tags that may be present on the same line.\n"
   ],
   "id": "49ed555681157330"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.013004Z",
     "start_time": "2024-10-15T15:01:17.010734Z"
    }
   },
   "cell_type": "code",
   "source": "from urllib.request import urlopen",
   "id": "18a8e01dcdd1f0c1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.281433Z",
     "start_time": "2024-10-15T15:01:17.068716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "html_page = urlopen(url)\n",
    "html_text = html_page.read().decode(\"utf-8\")"
   ],
   "id": "eb71f61c68e27a6e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.302901Z",
     "start_time": "2024-10-15T15:01:17.299040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for string in [\"Name: \", \"Favorite Color:\"]:\n",
    "    string_start_idx = html_text.find(string)\n",
    "    text_start_idx = string_start_idx + len(string)\n",
    "\n",
    "    next_html_tag_offset = html_text[text_start_idx:].find(\"<\")\n",
    "    text_end_idx = text_start_idx + next_html_tag_offset\n",
    "\n",
    "    raw_text = html_text[text_start_idx : text_end_idx]\n",
    "    clean_text = raw_text.strip(\" \\r\\n\\t\")\n",
    "    print(clean_text)"
   ],
   "id": "f4145c0318fb8093",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dionysus\n",
      "Wine\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "bd4712d9967893ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. - Parsing HTML Content With an HTML Parser\n",
    "\n",
    "While regular expressions are powerful for pattern matching, using an HTML parser specifically designed for parsing HTML pages can often be more straightforward. There are several Python tools available for this purpose, but the [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) library is an excellent choice for beginners.\n"
   ],
   "id": "faab8557d6bf907f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.1 - Install the `beautifulsoup4` Package\n",
    "\n",
    "You can install Beautiful Soup using pip:\n",
    "\n",
    "```bash\n",
    "pip install beautifulsoup4\n",
    "```\n",
    "\n",
    "Because we defined a requirement file, you can install all the packages needed for this class by running the following command:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ],
   "id": "f6210e98d2a6cf4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 - Import the `BeautifulSoup` Class and Create a BeautifulSoup Object",
   "id": "c2789fb09e7508cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.664098Z",
     "start_time": "2024-10-15T15:01:17.366292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "soup"
   ],
   "id": "faffbc73229ccad6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>Profile: Dionysus</title>\n",
       "</head>\n",
       "<body bgcolor=\"yellow\">\n",
       "<center>\n",
       "<br/><br/>\n",
       "<img src=\"/static/dionysus.jpg\"/>\n",
       "<h2>Name: Dionysus</h2>\n",
       "<img src=\"/static/grapes.png\"/><br/><br/>\n",
       "Hometown: Mount Olympus\n",
       "<br/><br/>\n",
       "Favorite animal: Leopard <br/>\n",
       "<br/>\n",
       "Favorite Color: Wine\n",
       "</center>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This code performs three main tasks:\n",
    "\n",
    "1. Opens the URL [http://olympus.realpython.org/profiles/dionysus](http://olympus.realpython.org/profiles/dionysus) using `urlopen()` from the `urllib.request` module.\n",
    "\n",
    "2. Reads the HTML from the page as a string and assigns it to the `html` variable.\n",
    "\n",
    "3. Creates a BeautifulSoup object, assigning it to the `soup` variable.\n",
    "\n",
    "The BeautifulSoup object created and assigned to `soup` is initialized with two arguments. The first argument is the HTML to be parsed, while the second argument, `\"html.parser\"`, specifies the parser to use. This indicates that Python's built-in HTML parser should be employed.\n"
   ],
   "id": "c8e7721a662a6dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.3 - Using a BeautifulSoup Object\n",
    "\n",
    "For instance, BeautifulSoup objects include a `.get_text()` method that allows you to extract all the text from the document while automatically removing any HTML tags."
   ],
   "id": "a85eb77d8fd247b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.683093Z",
     "start_time": "2024-10-15T15:01:17.680315Z"
    }
   },
   "cell_type": "code",
   "source": "print(soup.get_text())",
   "id": "c082b0ed12f3c574",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Profile: Dionysus\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: Dionysus\n",
      "\n",
      "Hometown: Mount Olympus\n",
      "\n",
      "Favorite animal: Leopard \n",
      "\n",
      "Favorite Color: Wine\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The output contains many blank lines, which are caused by newline characters in the HTML document's text. If necessary, you can remove these blank lines using the `.replace()` string method.",
   "id": "fb8552f39a314d19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.4 - Extracting Text From the HTML using BeautifulSoup\n",
    "\n",
    "Frequently, you may want to extract only specific text from an HTML document. In such cases, using Beautiful Soup to extract the text and then applying the `.find()` string method can be easier than working directly with regular expressions.\n",
    "\n",
    "However, there are times when the HTML tags themselves indicate the data you want to retrieve. For example, if you want to gather the URLs for all the images on a page, these links are found in the `src` attribute of `<img>` HTML tags.\n",
    "\n",
    "In this scenario, you can use `find_all()` to return a list of all instances of that specific tag:\n"
   ],
   "id": "fc0538dc5a3c6710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.754750Z",
     "start_time": "2024-10-15T15:01:17.750913Z"
    }
   },
   "cell_type": "code",
   "source": "soup.find_all(\"img\")",
   "id": "4fe19ce9ad9f711a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img src=\"/static/dionysus.jpg\"/>, <img src=\"/static/grapes.png\"/>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This will return a list of all `<img>` tags in the HTML document. Although the objects in the list may appear to be strings representing the tags, they are actually instances of the Tag object provided by Beautiful Soup. Tag objects offer a straightforward interface for interacting with the information they contain.\n",
   "id": "243b19cfdacc6237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.783658Z",
     "start_time": "2024-10-15T15:01:17.781238Z"
    }
   },
   "cell_type": "code",
   "source": "image1, image2 = soup.find_all(\"img\")",
   "id": "d7030f525920f72",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Each Tag object has a .name property that returns a string containing the HTML tag type:",
   "id": "df08734a295b0106"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.831305Z",
     "start_time": "2024-10-15T15:01:17.828086Z"
    }
   },
   "cell_type": "code",
   "source": "image1.name",
   "id": "af62b8891ec4b815",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can access the HTML attributes of a Tag object by placing their names within square brackets, similar to how you would access values in a dictionary.\n",
    "\n",
    "For instance, the `<img src=\"/static/dionysus.jpg\"/>` tag has a single attribute, `src`, with the value `\"/static/dionysus.jpg\"`. Similarly, an HTML tag like the link `<a href=\"https://realpython.com\" target=\"_blank\">` has two attributes, `href` and `target`.\n",
    "\n",
    "To retrieve the source of the images on the Dionysus profile page, you can access the `src` attribute using the dictionary notation described above:\n"
   ],
   "id": "e7c8f19bad6484e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can check the attributes of a Tag object by using the `.attrs` property:",
   "id": "4167ecaef4ad10ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.871934Z",
     "start_time": "2024-10-15T15:01:17.867908Z"
    }
   },
   "cell_type": "code",
   "source": "image1.attrs",
   "id": "11e6f94494ead768",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': '/static/dionysus.jpg'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Certain tags in HTML documents can be accessed through properties of the Tag object. For example, to retrieve the `<title>` tag in a document, you can use the `.title` property:",
   "id": "24772a6871c08e06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.949302Z",
     "start_time": "2024-10-15T15:01:17.946006Z"
    }
   },
   "cell_type": "code",
   "source": "soup.title",
   "id": "56b4884bcfd2271f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Profile: Dionysus</title>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:17.986715Z",
     "start_time": "2024-10-15T15:01:17.983581Z"
    }
   },
   "cell_type": "code",
   "source": "soup.title.string",
   "id": "8713c0f8ea5dda74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Profile: Dionysus'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "fd1f9c7b92c4e295"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. - Check Your Understanding\n",
    "\n",
    "### Write a program that grabs the full HTML from the following URL:\n",
    "\n",
    "### [http://olympus.realpython.org/profiles](http://olympus.realpython.org/profiles)\n",
    "\n",
    "### Next, use Beautiful Soup to extract a list of all the links on the page by looking for HTML tags with the name `a` and retrieving the value taken on by the href attribute of each tag.\n",
    "\n",
    "### The final output should look like this:\n",
    "\n",
    "```shell\n",
    "http://olympus.realpython.org/profiles/aphrodite\n",
    "http://olympus.realpython.org/profiles/poseidon\n",
    "http://olympus.realpython.org/profiles/dionysus\n",
    "```\n"
   ],
   "id": "91f8fb4bffe5d713"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:18.042707Z",
     "start_time": "2024-10-15T15:01:18.040063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ],
   "id": "ebb9b519ec46b1cd",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:18.063413Z",
     "start_time": "2024-10-15T15:01:18.060982Z"
    }
   },
   "cell_type": "code",
   "source": "base_url = \"http://olympus.realpython.org\"",
   "id": "3ff352bca72bdd9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:18.319018Z",
     "start_time": "2024-10-15T15:01:18.106941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "html_page = urlopen(base_url + \"/profiles\")\n",
    "html_text = html_page.read().decode(\"utf-8\")"
   ],
   "id": "1d38e9ff2ed3512f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:18.333447Z",
     "start_time": "2024-10-15T15:01:18.330769Z"
    }
   },
   "cell_type": "code",
   "source": "soup = BeautifulSoup(html_text, \"html.parser\")",
   "id": "d0fdf52448cbc36e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:18.381872Z",
     "start_time": "2024-10-15T15:01:18.378618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for link in soup.find_all(\"a\"):\n",
    "    link_url = base_url + link[\"href\"]\n",
    "    print(link_url)"
   ],
   "id": "687359f656b739b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://olympus.realpython.org/profiles/aphrodite\n",
      "http://olympus.realpython.org/profiles/poseidon\n",
      "http://olympus.realpython.org/profiles/dionysus\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "8bd956d8706ebe49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. - Interacting With Forms and Dynamic Web Elements\n",
    "\n",
    "The `urllib` module you've been using in this tutorial is great for requesting the contents of a web page. However, there are instances when you need to interact with a web page to obtain the necessary content. For example, you might need to submit a form or click a button to reveal hidden content.\n",
    "\n",
    "The Python standard library does not include built-in functionality for interacting with web pages, but many third-party packages are available on PyPI. One popular and relatively straightforward option is [MechanicalSoup](https://mechanicalsoup.readthedocs.io/en/stable/).\n",
    "\n",
    "Essentially, MechanicalSoup acts as a headless browser—a web browser that operates without a graphical user interface. This headless browser can be controlled programmatically through a Python script.\n"
   ],
   "id": "481887c79fd01572"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7.1 - Install the `mechanicalsoup` Package\n",
    "\n",
    "You can install MechanicalSoup using pip:\n",
    "\n",
    "```bash\n",
    "pip install MechanicalSoup\n",
    "```\n",
    "\n",
    "Because we defined a requirement file, you can install all the packages needed for this class by running the following command:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ],
   "id": "202f119d5b00864f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note: You may need to restart your Jupyter Notebook kernel after installing MechanicalSoup.**",
   "id": "9911c0931a8d5c53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.2 - Create a Browser Object",
   "id": "cebb0647a4733b43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:01:35.847551Z",
     "start_time": "2024-10-15T15:01:35.845180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mechanicalsoup as ms\n",
    "\n",
    "browser = ms.Browser()"
   ],
   "id": "ed02b49761d3f2fa",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Browser objects represent the headless web browser. You can utilize these objects to request a page from the Internet by passing a URL to their `.get()` method:",
   "id": "dbace85b8c3d176e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:02:22.329655Z",
     "start_time": "2024-10-15T15:02:21.984635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"http://olympus.realpython.org/login\"\n",
    "page = browser.get(url)\n",
    "page"
   ],
   "id": "29450b5b1a46b1ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The number 200 represents the status code returned by the request. A status code of 200 indicates that the request was successful. Conversely, an unsuccessful request might return a status code of 404 if the URL does not exist, or 500 if there is a server error during the request.\n",
   "id": "5bfa083b8ad68afc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "MechanicalSoup utilizes BeautifulSoup to parse the HTML obtained from the request. The `page` object includes a `.soup` attribute, which represents a BeautifulSoup object:",
   "id": "7abad3f0f1568622"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:07:27.556226Z",
     "start_time": "2024-10-15T15:07:27.553136Z"
    }
   },
   "cell_type": "code",
   "source": "type(page.soup)",
   "id": "2b3c16b8eb1f05f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:07:37.352179Z",
     "start_time": "2024-10-15T15:07:37.348061Z"
    }
   },
   "cell_type": "code",
   "source": "page.soup",
   "id": "2f00d72b00fb4dac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>Log In</title>\n",
       "</head>\n",
       "<body bgcolor=\"yellow\">\n",
       "<center>\n",
       "<br/><br/>\n",
       "<h2>Please log in to access Mount Olympus:</h2>\n",
       "<br/><br/>\n",
       "<form action=\"/login\" method=\"post\" name=\"login\">\n",
       "Username: <input name=\"user\" type=\"text\"/><br/>\n",
       "Password: <input name=\"pwd\" type=\"password\"/><br/><br/>\n",
       "<input type=\"submit\" value=\"Submit\"/>\n",
       "</form>\n",
       "</center>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Notice this page has a `<form>` on it with `<input>` elements for a username and a password.",
   "id": "1858c17c75763150"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.3 - Filling Out and Submitting a Form",
   "id": "44bf552e86d69959"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before proceeding, open the [/login](http://olympus.realpython.org/login) page from the previous example in a browser and take a look at it yourself.\n",
   "id": "ea4d47d80907cd07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Try entering a random username and password combination. If your guess is incorrect, the message \"Wrong username or password!\" will appear at the bottom of the page.\n",
    "\n",
    "On the other hand, if you enter the correct login credentials, you will be redirected to the [/profiles](http://olympus.realpython.org/profiles) page:\n",
    "\n",
    "| Username | Password       |\n",
    "|----------|----------------|\n",
    "| zeus     | ThunderDude    |\n"
   ],
   "id": "2ea9858ab4351a7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the following example, you'll learn how to use MechanicalSoup to fill out and submit this form using Python!\n",
    "\n",
    "The key part of the HTML code is the login form, which includes everything inside the `<form>` tags. This form has its `name` attribute set to \"login\" and contains two `<input>` elements: one named `user` and the other named `pwd`. Additionally, there is a third `<input>` element for the Submit button.\n",
    "\n",
    "With an understanding of the login form's structure and the required credentials, let's examine a program that fills out the form and submits it.\n"
   ],
   "id": "916166b8173465af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:15:26.616845Z",
     "start_time": "2024-10-15T15:15:26.043385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mechanicalsoup\n",
    "\n",
    "# 1\n",
    "browser = mechanicalsoup.Browser()\n",
    "url = \"http://olympus.realpython.org/login\"\n",
    "login_page = browser.get(url)\n",
    "login_html = login_page.soup\n",
    "\n",
    "# 2\n",
    "form = login_html.select(\"form\")[0]\n",
    "form.select(\"input\")[0][\"value\"] = \"zeus\"\n",
    "form.select(\"input\")[1][\"value\"] = \"ThunderDude\"\n",
    "\n",
    "# 3\n",
    "profiles_page = browser.submit(form, login_page.url)"
   ],
   "id": "6f8e412bbb96743b",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:15:43.171788Z",
     "start_time": "2024-10-15T15:15:43.167651Z"
    }
   },
   "cell_type": "code",
   "source": "profiles_page.url",
   "id": "232584c529dc211c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://olympus.realpython.org/profiles'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, let's break down the example:\n",
    "\n",
    "1. You create a `Browser` instance and use it to request the URL `http://olympus.realpython.org/login`. The HTML content of the page is assigned to the `login_html` variable using the `.soup` property.\n",
    "\n",
    "2. `login_html.select(\"form\")` returns a list of all `<form>` elements on the page. Since there is only one `<form>` element, you can access it by retrieving the element at index 0 of the list. Alternatively, if there's only one form on the page, you can also use `login_html.form`.\n",
    "\n",
    "3. The next two lines select the username and password input fields and set their values to \"zeus\" and \"ThunderDude\", respectively.\n",
    "\n",
    "4. You submit the form using `browser.submit()`. Note that you pass two arguments to this method: the form object and the URL of the login page, which you can access via `login_page.url`.\n",
    "\n",
    "5. In the interactive window, you confirm that the submission successfully redirected to the `/profiles` page. If something had gone wrong, the value of `profiles_page.url` would still be `\"http://olympus.realpython.org/login\"`.\n"
   ],
   "id": "635da44fd3f79b6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now that you have the `profiles_page` variable set, it's time to programmatically obtain the URL for each link on the `/profiles` page.\n",
    "\n",
    "To achieve this, you can use the `.select()` method again, this time passing the string `\"a\"` to select all `<a>` anchor elements on the page:\n"
   ],
   "id": "993774cebd424c13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:28:35.574232Z",
     "start_time": "2024-10-15T15:28:35.570528Z"
    }
   },
   "cell_type": "code",
   "source": "links = profiles_page.soup.select(\"a\")",
   "id": "319389af5371f6e7",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:28:50.262720Z",
     "start_time": "2024-10-15T15:28:50.256894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for link in links:\n",
    "    address = link[\"href\"]\n",
    "    text = link.text\n",
    "    print(f\"{text}: {address}\")"
   ],
   "id": "e20435f4f1157adf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aphrodite: /profiles/aphrodite\n",
      "Poseidon: /profiles/poseidon\n",
      "Dionysus: /profiles/dionysus\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The URLs contained in each `href` attribute are relative URLs, which can be less useful if you want to navigate to them later using MechanicalSoup. If you know the full URL, you can easily construct the complete URL.\n",
    "\n",
    "In this case, the base URL is `http://olympus.realpython.org`. You can concatenate this base URL with the relative URLs found in the `href` attributes to form complete URLs.\n"
   ],
   "id": "91c9c761306d2d16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:30:03.622016Z",
     "start_time": "2024-10-15T15:30:03.614977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_url = \"http://olympus.realpython.org\"\n",
    "for link in links:\n",
    "    address = base_url + link[\"href\"]\n",
    "    text = link.text\n",
    "    print(f\"{text}: {address}\")"
   ],
   "id": "432d7a4942688e75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aphrodite: http://olympus.realpython.org/profiles/aphrodite\n",
      "Poseidon: http://olympus.realpython.org/profiles/poseidon\n",
      "Dionysus: http://olympus.realpython.org/profiles/dionysus\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "35afb6128a744920"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. - Check Your Understanding\n",
    "\n",
    "### Use MechanicalSoup to provide the correct username (zeus) and password (ThunderDude) to the login form located at the URL http://olympus.realpython.org/login.\n",
    "\n",
    "### Once the form is submitted, display the title of the current page to determine that you’ve been redirected to the /profiles page.\n",
    "\n",
    "### Your program should print the text `<title>All Profiles</title>`.\n",
    "\n"
   ],
   "id": "4549588dada0d90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:45:27.428833Z",
     "start_time": "2024-10-18T09:45:27.235906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mechanicalsoup\n",
    "\n",
    "browser = mechanicalsoup.Browser()"
   ],
   "id": "f4a730333a390156",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:45:27.884598Z",
     "start_time": "2024-10-18T09:45:27.475049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "login_url = \"http://olympus.realpython.org/login\"\n",
    "login_page = browser.get(login_url)\n",
    "login_html = login_page.soup"
   ],
   "id": "5be0ea4b6443762",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:45:28.013170Z",
     "start_time": "2024-10-18T09:45:28.009696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "form = login_html.form\n",
    "form.select(\"input\")[0][\"value\"] = \"zeus\"\n",
    "form.select(\"input\")[1][\"value\"] = \"ThunderDude\""
   ],
   "id": "93f09517b9c88cf7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:45:28.314817Z",
     "start_time": "2024-10-18T09:45:28.056291Z"
    }
   },
   "cell_type": "code",
   "source": "profiles_page = browser.submit(form, login_page.url)",
   "id": "32d019fc87ae04e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:45:28.934459Z",
     "start_time": "2024-10-18T09:45:28.930450Z"
    }
   },
   "cell_type": "code",
   "source": "print(profiles_page.soup.title)",
   "id": "84b3f12b93c79a08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>All Profiles</title>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:46:37.345527Z",
     "start_time": "2024-10-18T09:46:37.341687Z"
    }
   },
   "cell_type": "code",
   "source": "links = profiles_page.soup.select(\"a\")",
   "id": "7c66906167e5a9ac",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:46:38.777731Z",
     "start_time": "2024-10-18T09:46:38.768605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_url = \"http://olympus.realpython.org\"\n",
    "all_links = []\n",
    "for link in links:\n",
    "    address = base_url + link[\"href\"]\n",
    "    text = link.text\n",
    "    print(f\"{text}: {address}\")\n",
    "    all_links.append(address)\n",
    "    \n",
    "all_links"
   ],
   "id": "5753de7685b91229",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aphrodite: http://olympus.realpython.org/profiles/aphrodite\n",
      "Poseidon: http://olympus.realpython.org/profiles/poseidon\n",
      "Dionysus: http://olympus.realpython.org/profiles/dionysus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://olympus.realpython.org/profiles/aphrodite',\n",
       " 'http://olympus.realpython.org/profiles/poseidon',\n",
       " 'http://olympus.realpython.org/profiles/dionysus']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:47:03.282348Z",
     "start_time": "2024-10-18T09:47:02.886359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for link in all_links:\n",
    "    page = browser.get(link)\n",
    "    print(page.soup.title.string)"
   ],
   "id": "4569d2cf07517517",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: Aphrodite\n",
      "Profile: Poseidon\n",
      "Profile: Dionysus\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "8e6681126b6c8477"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. - Interacting With Websites in Real Time\n",
    "\n",
    "Sometimes, you may want to fetch real-time data from a website that provides continually updated information.\n",
    "\n",
    "In the past, before learning Python programming, you might have had to sit in front of a browser, clicking the Refresh button to reload the page every time you wanted to check for updated content. Now, you can automate this process using the `.get()` method of the MechanicalSoup Browser object.\n",
    "\n",
    "To see this in action, open your preferred browser and navigate to the URL: [http://olympus.realpython.org/dice](http://olympus.realpython.org/dice).\n"
   ],
   "id": "9426f4db2c895bc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The [/dice](http://olympus.realpython.org/dice) page simulates a roll of a six-sided die, updating the result with each browser refresh. Below, you'll write a program that repeatedly scrapes the page for a new result.\n",
    "\n",
    "First, you need to identify which element on the page contains the die roll result. To do this, right-click anywhere on the page and select **View Page Source**. Look for an `<h2>` tag about halfway down the HTML code that appears as follows:\n",
    "\n",
    "```html\n",
    "<h2 id=\"result\">3</h2>\n",
    "```\n",
    "\n"
   ],
   "id": "c1a124dbc65874f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 9.1 - To begin, write a simple program that opens the `/dice` page, scrapes the result, and prints it to the console. Here’s a basic example to get you started:",
   "id": "4e03a224ce579dbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:49:37.367540Z",
     "start_time": "2024-10-18T09:49:36.993214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import mechanicalsoup\n",
    "\n",
    "browser = mechanicalsoup.Browser()\n",
    "page = browser.get(\"http://olympus.realpython.org/dice\")\n",
    "page.soup"
   ],
   "id": "e177582e3003e910",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>Dice Roll</title>\n",
       "</head>\n",
       "<body bgcolor=\"yellow\">\n",
       "<center>\n",
       "<br/><br/>\n",
       "<h1>Your dice roll result:</h1>\n",
       "<br/>\n",
       "<h2 id=\"result\">3</h2>\n",
       "<br/>\n",
       "<p><a href=\"/dice\">Roll it again</a></p>\n",
       "<br/>\n",
       "<br/>\n",
       "<p id=\"time\">October 18, 2024 09:49:37AM</p>\n",
       "</center>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T09:49:40.626667Z",
     "start_time": "2024-10-18T09:49:40.621892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tag = page.soup.select(\"#result\")[0]\n",
    "result = tag.text\n",
    "\n",
    "print(f\"The result of your dice roll is: {result}\")"
   ],
   "id": "d13554981012100e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of your dice roll is: 3\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This example uses the `BeautifulSoup` object’s `.select()` method to find the element with `id=result`. The string `#result`, which you pass to `.select()`, utilizes the CSS ID selector `#` to indicate that `result` is an ID value.\n",
    "\n",
    "To periodically get a new result, you’ll need to create a loop that loads the page at each step. Therefore, everything below the line `browser = mechanicalsoup.Browser()` in the above code needs to be placed inside the loop.\n",
    "\n",
    "For this example, you want to roll the dice four times at ten-second intervals. To achieve this, the last line of your code needs to instruct Python to pause execution for ten seconds. You can do this with `time.sleep()` from Python’s time module. The `.sleep()` method takes a single argument that represents the amount of time to sleep in seconds.\n"
   ],
   "id": "43ba88c3ec139b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here’s an example that illustrates how sleep() works:",
   "id": "40772474df1e4fa8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:41:31.883473Z",
     "start_time": "2024-10-15T15:41:26.877390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "print(\"I'm about to wait for five seconds...\")\n",
    "time.sleep(5)\n",
    "print(\"Done waiting!\")"
   ],
   "id": "994be4e6e3af3996",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm about to wait for five seconds...\n",
      "Done waiting!\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When you run this code, you’ll notice that the \"Done waiting!\" message isn’t displayed until five seconds have passed since the first `print()` function was executed.",
   "id": "138c9779dbca34de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 9.2 - Now, combine the code snippets above to create a program that rolls the die four times at ten-second intervals:",
   "id": "7915dca8f40a8330"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:43:51.078850Z",
     "start_time": "2024-10-15T15:43:10.402264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import mechanicalsoup\n",
    "\n",
    "browser = mechanicalsoup.Browser()\n",
    "\n",
    "for i in range(4):\n",
    "    page = browser.get(\"http://olympus.realpython.org/dice\")\n",
    "    tag = page.soup.select(\"#result\")[0]\n",
    "    result = tag.text\n",
    "    print(f\"The result of your dice roll is: {result}\")\n",
    "    time.sleep(10)"
   ],
   "id": "18484315d90b07e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of your dice roll is: 5\n",
      "The result of your dice roll is: 1\n",
      "The result of your dice roll is: 5\n",
      "The result of your dice roll is: 5\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "When you run the program, you’ll immediately see the first result printed to the console. After ten seconds, the second result is displayed, then the third, and finally the fourth. What happens after the fourth result is printed?\n",
    "\n",
    "The program continues running for another ten seconds before it finally stops. That’s kind of a waste of time! You can stop it from doing this by using an if statement to run `time.sleep()` for only the first three requests:\n"
   ],
   "id": "ee1c46352b40171b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T15:46:04.356109Z",
     "start_time": "2024-10-15T15:45:33.655179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import mechanicalsoup\n",
    "\n",
    "browser = mechanicalsoup.Browser()\n",
    "\n",
    "for i in range(4):\n",
    "    page = browser.get(\"http://olympus.realpython.org/dice\")\n",
    "    tag = page.soup.select(\"#result\")[0]\n",
    "    result = tag.text\n",
    "    print(f\"The result of your dice roll is: {result}\")\n",
    "\n",
    "    # Wait 10 seconds if this isn't the last request\n",
    "    if i < 3:\n",
    "        time.sleep(10)"
   ],
   "id": "9c77b4ab2dda9811",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of your dice roll is: 3\n",
      "The result of your dice roll is: 6\n",
      "The result of your dice roll is: 3\n",
      "The result of your dice roll is: 2\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**With techniques like this, you can scrape data from websites that periodically update their data. However, you should be aware that requesting a page multiple times in rapid succession can be seen as suspicious, or even malicious, use of a website.**\n",
   "id": "62aa12494ab6ce51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It’s even possible to crash a server with an excessive number of requests, so you can imagine that many websites are concerned about the volume of requests to their server! Always check the Terms of Use and be respectful when sending multiple requests to a website.\n",
   "id": "37a803d52665b68a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "b5cd44a225c3b1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conclusion",
   "id": "e6224518e855cb7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Although it’s possible to parse data from the Web using tools in Python’s standard library, there are many tools on PyPI that can help simplify the process.\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "- Request a web page using Python’s built-in urllib module\n",
    "- Parse HTML using Beautiful Soup\n",
    "- Interact with web forms using MechanicalSoup\n",
    "- Repeatedly request data from a website to check for updates\n",
    "\n",
    "Writing automated web scraping programs is fun, and the Internet has no shortage of content that can lead to all sorts of exciting projects.\n",
    "\n",
    "Just remember, not everyone wants you pulling data from their web servers. Always check a website’s Terms of Use before you start scraping, and be respectful about how you time your web requests so that you don’t flood a server with traffic.\n"
   ],
   "id": "49705dba3e640ce1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "367e1c6648b006c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Additional Resources\n",
    "\n"
   ],
   "id": "1ee4809143813d97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For more information on web scraping with Python, check out the following resources:\n",
    "\n",
    "- [Beautiful Soup: Build a Web Scraper With Python](https://realpython.com/beautiful-soup-web-scraper-python/)\n",
    "- [urllib Documentation](https://docs.python.org/3/library/urllib.html)\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [MechanicalSoup documentation](https://mechanicalsoup.readthedocs.io/en/stable/)"
   ],
   "id": "17846e2d9f04168e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
