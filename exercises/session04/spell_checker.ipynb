{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Spell Checker"
   ],
   "id": "4c180dc1275d8ab0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Another possible use of text similarity is to correct spelling mistakes. For instance, lets say weâ€™ve got the following text written incorrectly:\n",
    "\n",
    "\"it could be a greal busines\"\n",
    "\n",
    "Humans can easily spot spelling mistakes by checking a dictionary, but this task is more challenging for a computer. In this section, we will use **NLTK** and the **Jaccard distance** to implement a basic spell checker.\n",
    "\n",
    "### What Do We Need to Create a Spell Checker?\n",
    "1. **A Corpus**: This serves as the ground truth or the source of correct spellings. In our case, the corpus is the dictionary we consult for corrections.\n",
    "2. **A Method**: To find the most similar word from the corpus based on a misspelled word. We will use the Jaccard similarity for this task.\n",
    "\n",
    "### Using n-grams:\n",
    "Instead of comparing words letter by letter, we will compare them by breaking them into **n-grams**, which represent sequences of `n` characters. This allows us to compare based on minimal units of similarity, improving the matching process for our spell checker."
   ],
   "id": "10e240b17885416c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Computing n-grams using NLTK:"
   ],
   "id": "c21d80de49b01e4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T09:40:58.140604Z",
     "start_time": "2024-09-27T09:40:58.134185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Set\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def ngram_gen(word: str, n: int) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Generate n-grams from a word.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word: str\n",
    "        The word to generate n-grams from.\n",
    "    n: int\n",
    "        The size of the n-grams.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Set[str]\n",
    "        A set of n-grams.\n",
    "    \"\"\"\n",
    "    n_grams = ngrams(word, n)\n",
    "    \n",
    "    return set(n_grams)\n",
    "\n",
    "# test the function\n",
    "word = \"test\"\n",
    "ngram_gen(word, 2)"
   ],
   "id": "408b21d00a2e383d",
   "outputs": [
    {
     "data": {
      "text/plain": "{('e', 's'), ('s', 't'), ('t', 'e')}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Suggestions for a Misspelled Word:\n",
    "\n",
    "For that we need:\n",
    "- A corpus (NLTK provides a corpus of words).\n",
    "- A method to find the most similar word from the corpus based on a misspelled word. We will use the Jaccard similarity for this task.\n",
    "    "
   ],
   "id": "84c224bf2e579a72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T10:00:59.420747Z",
     "start_time": "2024-09-27T10:00:59.063956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "import nltk\n",
    "\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "def get_recommended_word(word: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Get the most similar word from a corpus based on the Jaccard similarity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word: str\n",
    "        The misspelled word.\n",
    "    corpus: Set[str]\n",
    "        The corpus of words.\n",
    "    n: int\n",
    "        The size of the n-grams.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The most similar word from the corpus.\n",
    "    \"\"\"\n",
    "    if len(word) < n:\n",
    "        return word\n",
    "    \n",
    "    # get our corpus of words\n",
    "    corpus = set(words.words())\n",
    "    \n",
    "    # generate n-grams for the misspelled word\n",
    "    word_ngrams = ngram_gen(word, n)\n",
    "    \n",
    "    # calculate the Jaccard similarity between the n-grams of the misspelled word and the n-grams of the corpus\n",
    "    similarities = {}\n",
    "    for w in corpus:\n",
    "        if w.startswith(word[:2]):\n",
    "            w_ngrams = ngram_gen(w, n)\n",
    "            jac = jaccard_distance(word_ngrams, w_ngrams)\n",
    "            similarities[w] = jac\n",
    "            if jac < 0.6:  \n",
    "                print(w, jac)\n",
    "    # get the word with the highest Jaccard similarity\n",
    "    recommended_word = min(similarities, key=similarities.get)\n",
    "    \n",
    "    return recommended_word\n",
    "\n",
    "# test the function\n",
    "sentence = \"it could be a greal busines\"\n",
    "corrected_sentence = \" \".join([get_recommended_word(word) for word in sentence.split()])\n",
    "corrected_sentence"
   ],
   "id": "b0812743ce8b23b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/tiago/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldron 0.5\n",
      "coul 0.3333333333333333\n",
      "could 0.0\n",
      "great 0.5\n",
      "businessman 0.4444444444444444\n",
      "busine 0.2\n",
      "businesslike 0.5\n",
      "businesslikeness 0.5833333333333334\n",
      "businesswoman 0.5454545454545454\n",
      "business 0.16666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": "'it could be a great business'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T09:55:40.596958Z",
     "start_time": "2024-09-27T09:55:37.882008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# another test (sentence with a misspelled words)\n",
    "sentence = \"i love to eat choclate\"\n",
    "corrected_sentence = \" \".join([get_recommended_word(word) for word in sentence.split()])\n",
    "corrected_sentence"
   ],
   "id": "e28438a389a9c5d8",
   "outputs": [
    {
     "data": {
      "text/plain": "'i love to eat chocolate'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T10:01:02.373194Z",
     "start_time": "2024-09-27T10:01:02.034237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# another test (sentence with a misspelled words) \n",
    "# it will fail\n",
    "sentence = \"i love to eat appls\"\n",
    "corrected_sentence = \" \".join([get_recommended_word(word) for word in sentence.split()])\n",
    "corrected_sentence"
   ],
   "id": "a25f7bbfe7ffb95c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lover 0.3333333333333333\n",
      "love 0.0\n",
      "lovely 0.5\n",
      "eat 0.0\n",
      "eats 0.5\n",
      "apply 0.5\n",
      "apple 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "'i love to eat apply'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "248a44f96b0a2906"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
