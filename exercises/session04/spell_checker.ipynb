{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Spell Checker"
   ],
   "id": "4c180dc1275d8ab0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Another possible use of text similarity is to correct spelling mistakes. For instance, lets say weâ€™ve got the following text written incorrectly:\n",
    "\n",
    "\"it could be a greal busines\"\n",
    "\n",
    "Humans can easily spot spelling mistakes by checking a dictionary, but this task is more challenging for a computer. In this section, we will use **NLTK** and the **Jaccard distance** to implement a basic spell checker.\n",
    "\n",
    "### What Do We Need to Create a Spell Checker?\n",
    "1. **A Corpus**: This serves as the ground truth or the source of correct spellings. In our case, the corpus is the dictionary we consult for corrections.\n",
    "2. **A Method**: To find the most similar word from the corpus based on a misspelled word. We will use the Jaccard similarity for this task.\n",
    "\n",
    "### Using n-grams:\n",
    "Instead of comparing words letter by letter, we will compare them by breaking them into **n-grams**, which represent sequences of `n` characters. This allows us to compare based on minimal units of similarity, improving the matching process for our spell checker."
   ],
   "id": "10e240b17885416c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Computing n-grams using NLTK:"
   ],
   "id": "c21d80de49b01e4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T09:41:35.341322600Z",
     "start_time": "2024-09-27T09:41:35.315432900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Set\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def ngram_gen(word: str, n: int) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Generate n-grams from a word.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word: str\n",
    "        The word to generate n-grams from.\n",
    "    n: int\n",
    "        The size of the n-grams.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Set[str]\n",
    "        A set of n-grams.\n",
    "    \"\"\"\n",
    "    n_grams = ngrams(word, n)\n",
    "    \n",
    "    return set(n_grams)\n",
    "\n",
    "# test the function\n",
    "word = \"test\"\n",
    "ngram_gen(word, 2)"
   ],
   "id": "408b21d00a2e383d",
   "outputs": [
    {
     "data": {
      "text/plain": "{('e', 's'), ('s', 't'), ('t', 'e')}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Suggestions for a Misspelled Word:\n",
    "\n",
    "For that we need:\n",
    "- A corpus (NLTK provides a corpus of words).\n",
    "- A method to find the most similar word from the corpus based on a misspelled word. We will use the Jaccard similarity for this task.\n",
    "    "
   ],
   "id": "84c224bf2e579a72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T11:46:13.128137Z",
     "start_time": "2024-09-22T11:46:12.711980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "import nltk\n",
    "\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "def get_recommended_word(word: str, n: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Get the most similar word from a corpus based on the Jaccard similarity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word: str\n",
    "        The misspelled word.\n",
    "    corpus: Set[str]\n",
    "        The corpus of words.\n",
    "    n: int\n",
    "        The size of the n-grams.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The most similar word from the corpus.\n",
    "    \"\"\"\n",
    "    if len(word) < n:\n",
    "        return word\n",
    "    \n",
    "    # get our corpus of words\n",
    "    corpus = set(words.words())\n",
    "    \n",
    "    # generate n-grams for the misspelled word\n",
    "    word_ngrams = ngram_gen(word, n)\n",
    "    \n",
    "    # calculate the Jaccard similarity between the n-grams of the misspelled word and the n-grams of the corpus\n",
    "    similarities =\n",
    "    for w in corpus:\n",
    "        w_ngrams = ngram_gen(w, n)\n",
    "        jac = jaccard_distance(word_ngrams, w_ngrams)\n",
    "        similarities[w] = jac\n",
    "    \n",
    "    # get the word with the highest Jaccard similarity\n",
    "    recommended_word = ...\n",
    "    \n",
    "    return recommended_word\n",
    "\n",
    "# test the function\n",
    "sentence = \"it could be a greal busines\"\n",
    "corrected_sentence = \" \".join([get_recommended_word(word) for word in sentence.split()])\n",
    "corrected_sentence"
   ],
   "id": "b0812743ce8b23b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'it could be a great business'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T11:47:41.150601Z",
     "start_time": "2024-09-22T11:47:40.707828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# another test (sentence with a misspelled words)\n",
    "sentence = \"i love to eat choclate\"\n",
    "corrected_sentence = \" \".join([get_recommended_word(word) for word in sentence.split()])\n",
    "corrected_sentence"
   ],
   "id": "e28438a389a9c5d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love to eat chocolate'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T11:48:35.687780Z",
     "start_time": "2024-09-22T11:48:35.248355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# another test (sentence with a misspelled words) \n",
    "# it will fail\n",
    "sentence = \"i love to eat appls\"\n",
    "corrected_sentence = \" \".join([get_recommended_word(word) for word in sentence.split()])\n",
    "corrected_sentence"
   ],
   "id": "a25f7bbfe7ffb95c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love to eat apply'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/News_Category_Dataset_v3.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../../data/News_Category_Dataset_v3.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      2\u001B[0m     data \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m      4\u001B[0m data\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tac-hands-on\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n\u001B[1;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../data/News_Category_Dataset_v3.json'"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/News_Category_Dataset_v3.json\", 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T14:49:54.882392900Z",
     "start_time": "2024-10-10T14:49:54.831020200Z"
    }
   },
   "id": "3022c85f0c7ab38b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T14:49:57.553833Z",
     "start_time": "2024-10-10T14:49:57.537036900Z"
    }
   },
   "id": "2820fc831cb4d52f",
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
