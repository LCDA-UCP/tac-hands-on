{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Named Entity Recognition (NER) Exercises\n",
    "\n",
    "## Overview of Named Entity Recognition (NER)\n",
    "Named Entity Recognition (NER) is a key task in Natural Language Processing (NLP) that involves identifying and classifying named entities in text into predefined categories such as the names of people, organizations, locations, dates, etc.\n",
    "\n",
    "NER helps systems to understand and extract important information from text, which is useful in tasks like document summarization, question answering, and knowledge extraction.\n",
    "\n",
    "### Common Entity Types:\n",
    "- **PERSON**: Names of people, e.g., \"Albert Einstein\"\n",
    "- **LOCATION**: Geopolitical entities, cities, countries, etc., e.g., \"Paris\"\n",
    "- **ORGANIZATION**: Company names, agencies, etc., e.g., \"Google\"\n",
    "- **DATE**: Specific dates or time expressions, e.g., \"July 4, 1776\"\n",
    "- **MISC**: Other categories like events, laws, etc., e.g., \"World War II\"\n"
   ],
   "id": "1bd72e91420e99fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NER in NLTK\n",
    "\n",
    "### 1. Importing Required Libraries\n",
    "To start working with NER in NLTK, we need the `nltk` library and its pretrained models. \n",
    "\n",
    "First, make sure you have NLTK installed and download the necessary resources:\n",
    "\n",
    "```bash\n",
    "pip install nltk\n",
    "```"
   ],
   "id": "733e9edc6dd6a3df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:13:28.602247Z",
     "start_time": "2024-11-06T21:13:27.561774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from scipy.special import which\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ],
   "id": "cd8d7d41d118ae03",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joao-correia/anaconda3/envs/tac-hands-on/lib/python3.10/site-packages/nltk/metrics/association.py:26: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.22.4)\n",
      "  from scipy.stats import fisher_exact\n",
      "[nltk_data] Downloading package punkt to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Tokenizing Text\n",
    "\n",
    "Before we can apply NER, we need to tokenize the text into words. Implement a function that takes a text string as input and returns a list of words."
   ],
   "id": "3dd86d871c7ca10f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:14:56.658374Z",
     "start_time": "2024-11-06T21:14:56.655912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add code here"
   ],
   "id": "eef1af83df36ce2a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Part-of-Speech Tagging\n",
    "\n",
    "Next, we perform part-of-speech (POS) tagging to mark words with their grammatical categories. This helps the NER model identify entities correctly.\n",
    "\n",
    "Implement a function that takes a list of words as input and returns a list of tuples where each tuple contains a word and its POS tag."
   ],
   "id": "31b66912e8c5ffd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:15:51.162921Z",
     "start_time": "2024-11-06T21:15:51.160400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add code here"
   ],
   "id": "a2ebea095bd788b9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Named Entity Recognition\n",
    "\n",
    "Now, we apply NER which identifies named entities in the tokenized and tagged text.\n",
    "\n",
    "Implement a function that takes a list of word-POS tuples as input and returns a list of named entities found in the text."
   ],
   "id": "6e580d0e14cd7a0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:16:31.187527Z",
     "start_time": "2024-11-06T21:16:31.184677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add code here"
   ],
   "id": "5ca0a05e09df12c4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Extracting Named Entities from Text\n",
    "\n",
    "Finally, we put all the steps together to extract named entities from a given text string.\n",
    "\n",
    "Implement a function that takes a text string as input and returns a list of named entities found in the text.\n",
    "\n",
    "The output should be a list of tuples where each tuple contains the entity name and its category (e.g., 'PERSON', 'LOCATION', etc.).\n",
    "\n",
    "**Hint:** `ne_chunk` function returns a nested tree (nlkt.Tree) that can be traversed to extract named entities. E.g., `tree.label()` gives the entity type."
   ],
   "id": "62385f5946819c61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# add code here"
   ],
   "id": "315ef42e0b00bc5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. Categorizing Named Entities\n",
    "\n",
    "To make the output more readable, we can group the named entities by their categories.\n",
    "\n",
    "Implement a function that takes text as input and returns a dictionary where the keys are entity categories and the values are lists of entities belonging to that category."
   ],
   "id": "6aa55f475f53474"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# add code here"
   ],
   "id": "1a705ff0e8d38d95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing Named Entities with Spacy\n",
    "\n",
    "spaCy is an open-source software library for advanced Natural Language Processing (NLP) in Python. It's designed specifically for production use and offers a fast, efficient, and easy-to-use interface for text processing tasks. spaCy provides pre-trained models for various languages, making it highly effective for a wide range of NLP tasks, including:\n",
    "\n",
    "- Tokenization\n",
    "- Part-of-speech tagging\n",
    "- Named Entity Recognition (NER)\n",
    "- Dependency parsing\n",
    "- Text classification\n",
    "- Text similarity\n",
    "\n",
    "One of the key features of spaCy is its high performance. It is optimized for speed, making it suitable for processing large volumes of text. spaCy also provides integration with other powerful libraries like TensorFlow, PyTorch, and Scikit-learn for more advanced NLP tasks and machine learning.\n"
   ],
   "id": "45919a59968279d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# download en_core_web_sm model\n",
    "#!python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Barack Obama gave a speech in New York on November 10, 2024.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Visualize entities\n",
    "displacy.render(doc, style=\"ent\")"
   ],
   "id": "5114906c331c344f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "\n",
    "NER is an essential tool for extracting structured information from unstructured text. By practicing these exercises, you will gain a better understanding of how to build and improve NER systems using Python and NLTK."
   ],
   "id": "967cdf8a065e0518"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
