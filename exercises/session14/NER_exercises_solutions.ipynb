{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Named Entity Recognition (NER) Exercises\n",
    "\n",
    "## Overview of Named Entity Recognition (NER)\n",
    "Named Entity Recognition (NER) is a key task in Natural Language Processing (NLP) that involves identifying and classifying named entities in text into predefined categories such as the names of people, organizations, locations, dates, etc.\n",
    "\n",
    "NER helps systems to understand and extract important information from text, which is useful in tasks like document summarization, question answering, and knowledge extraction.\n",
    "\n",
    "### Common Entity Types:\n",
    "- **PERSON**: Names of people, e.g., \"Albert Einstein\"\n",
    "- **LOCATION**: Geopolitical entities, cities, countries, etc., e.g., \"Paris\"\n",
    "- **ORGANIZATION**: Company names, agencies, etc., e.g., \"Google\"\n",
    "- **DATE**: Specific dates or time expressions, e.g., \"July 4, 1776\"\n",
    "- **MISC**: Other categories like events, laws, etc., e.g., \"World War II\"\n"
   ],
   "id": "1bd72e91420e99fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NER in NLTK\n",
    "\n",
    "### 1. Importing Required Libraries\n",
    "To start working with NER in NLTK, we need the `nltk` library and its pretrained models. \n",
    "\n",
    "First, make sure you have NLTK installed and download the necessary resources:\n",
    "\n",
    "```bash\n",
    "pip install nltk\n",
    "```"
   ],
   "id": "733e9edc6dd6a3df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:33:59.736278Z",
     "start_time": "2024-11-06T21:33:58.888048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ],
   "id": "cd8d7d41d118ae03",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/joao-\n",
      "[nltk_data]     correia/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Tokenizing Text\n",
    "\n",
    "Before we can apply NER, we need to tokenize the text into words. Implement a function that takes a text string as input and returns a list of words."
   ],
   "id": "3dd86d871c7ca10f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:33:59.749327Z",
     "start_time": "2024-11-06T21:33:59.746894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)"
   ],
   "id": "eef1af83df36ce2a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Part-of-Speech Tagging\n",
    "\n",
    "Next, we perform part-of-speech (POS) tagging to mark words with their grammatical categories. This helps the NER model identify entities correctly.\n",
    "\n",
    "Implement a function that takes a list of words as input and returns a list of tuples where each tuple contains a word and its POS tag."
   ],
   "id": "31b66912e8c5ffd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:33:59.837168Z",
     "start_time": "2024-11-06T21:33:59.835304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pos_tag_text(words):\n",
    "    return pos_tag(words)"
   ],
   "id": "a2ebea095bd788b9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Named Entity Recognition\n",
    "\n",
    "Now, we apply NER which identifies named entities in the tokenized and tagged text.\n",
    "\n",
    "Implement a function that takes a list of word-POS tuples as input and returns a list of named entities found in the text."
   ],
   "id": "6e580d0e14cd7a0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:33:59.880679Z",
     "start_time": "2024-11-06T21:33:59.877883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_named_entities(pos_tagged_text):\n",
    "    return ne_chunk(pos_tagged_text)"
   ],
   "id": "5ca0a05e09df12c4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Extracting Named Entities from Text\n",
    "\n",
    "Finally, we put all the steps together to extract named entities from a given text string.\n",
    "\n",
    "Implement a function that takes a text string as input and returns a list of named entities found in the text.\n",
    "\n",
    "The output should be a list of tuples where each tuple contains the entity name and its category (e.g., 'PERSON', 'LOCATION', etc.).\n",
    "\n",
    "**Hint:** `ne_chunk` function returns a nested tree (nlkt.Tree) that can be traversed to extract named entities. E.g., `tree.label()` gives the entity type."
   ],
   "id": "62385f5946819c61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:34:00.245991Z",
     "start_time": "2024-11-06T21:33:59.927215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_named_entities(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    entities = ne_chunk(tags)\n",
    "    named_entities = []\n",
    "    \n",
    "    for subtree in entities:\n",
    "        if isinstance(subtree, nltk.Tree):\n",
    "            entity = \" \".join([word for word, tag in subtree])\n",
    "            entity_type = subtree.label()\n",
    "            named_entities.append((entity, entity_type))\n",
    "    \n",
    "    return named_entities\n",
    "\n",
    "# Test the function\n",
    "text = \"Bill Gates founded Microsoft in the United States.\"\n",
    "print(extract_named_entities(text))\n"
   ],
   "id": "315ef42e0b00bc5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bill', 'PERSON'), ('Gates', 'PERSON'), ('Microsoft', 'ORGANIZATION'), ('United States', 'GPE')]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. Categorizing Named Entities\n",
    "\n",
    "To make the output more readable, we can group the named entities by their categories.\n",
    "\n",
    "Implement a function that takes text as input and returns a dictionary where the keys are entity categories and the values are lists of entities belonging to that category."
   ],
   "id": "6aa55f475f53474"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:34:00.473411Z",
     "start_time": "2024-11-06T21:34:00.254012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def categorize_named_entities(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    entities = ne_chunk(tags)\n",
    "    categorized_entities = {}\n",
    "    \n",
    "    for subtree in entities:\n",
    "        if isinstance(subtree, nltk.Tree):\n",
    "            entity = \" \".join([word for word, tag in subtree])\n",
    "            entity_type = subtree.label()\n",
    "            if entity_type in categorized_entities:\n",
    "                categorized_entities[entity_type].append(entity)\n",
    "            else:\n",
    "                categorized_entities[entity_type] = [entity]\n",
    "    \n",
    "    return categorized_entities\n",
    "\n",
    "# Test the function\n",
    "text = \"Bill Gates founded Microsoft in the United States.\"\n",
    "print(categorize_named_entities(text))"
   ],
   "id": "1a705ff0e8d38d95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PERSON': ['Bill', 'Gates'], 'ORGANIZATION': ['Microsoft'], 'GPE': ['United States']}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualizing Named Entities with Spacy",
   "id": "6f3df8f17ac33605"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T21:34:22.718897Z",
     "start_time": "2024-11-06T21:34:22.417373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# download en_core_web_sm model\n",
    "#!python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Barack Obama gave a speech in New York on November 10, 2024.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Visualize entities\n",
    "displacy.render(doc, style=\"ent\")"
   ],
   "id": "a7e75d70a05cf3ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barack Obama\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " gave a speech in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    November 10, 2024\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "\n",
    "NER is an essential tool for extracting structured information from unstructured text. By practicing these exercises, you will gain a better understanding of how to build and improve NER systems using Python and NLTK."
   ],
   "id": "967cdf8a065e0518"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
