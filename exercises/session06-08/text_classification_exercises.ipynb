{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Text Classification Exercises",
   "id": "5455135070daf480"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 1: Dataset Exploration\n",
    "\n",
    "**Objective**: Familiarize yourself with the dataset.\n",
    "\n",
    "1. Load the **News Category Dataset** (News_Category_Dataset_v3.json), which contains approximately 210,000 news headlines from 2012 to 2022. **Hint: read the file with Python, parse it with the json library and convert it to a pandas DataFrame.** **Note: you need to extract the file from the zip archive before loading it.**\n",
    "2. Identify the target label.\n",
    "3. Which features do you find relevant for the classification task?\n",
    "4. Perform exploratory data analysis (EDA):\n",
    "   - Check for any missing values.\n",
    "   - Visualize the distribution of categories.\n"
   ],
   "id": "f6a004ba75b584a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f0ae9fc46f891e20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a982935caba9f460"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96481d1100210e87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 2: Text Preprocessing\n",
    "\n",
    "**Objective**: Prepare the text data for classification tasks.\n",
    "\n",
    "1. Preprocess the \"headline\" and \"short_description\" fields by performing the following steps:\n",
    "   - Convert all text to lowercase.\n",
    "   - Remove punctuation, digits, and any other irrelevant characters.\n",
    "   - Remove stop words.\n",
    "   - Apply either stemming or lemmatization.\n",
    "2. Observe how the data changes at each step of preprocessing.\n",
    "3. Create a new column that concatenates the processed \"headline\" and \"short_description\" fields."
   ],
   "id": "190f3e008f235d44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "35eabf9cfd8d3e6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f71aae3c9796fbb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "265b954a3e4fbb7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 3: Data Splitting\n",
    "\n",
    "**Objective**: Split the dataset into training and testing sets.\n",
    "\n",
    "1. Divide the data into **training** and **testing** sets.\n",
    "   - Use an appropriate train-test split ratio (e.g., 80-20 or 70-30).\n",
    "   - Ensure the split is **stratified** to maintain the distribution of categories.\n",
    "   "
   ],
   "id": "90a25d9a89306675"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c977860c53a1890"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aaaa2fdc0158351d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca6e246d45ec0338"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 4: Feature Extraction\n",
    "\n",
    "**Objective**: Convert the text data into numerical features.\n",
    "\n",
    "1. Apply one of the following feature extraction techniques:\n",
    "   - **Bag-of-Words (BoW)**\n",
    "   - **TF-IDF**\n",
    "   - Optionally, apply N-grams (unigrams, bigrams, etc.) before feature extraction.\n",
    "2. Use either the **sklearn** or **nltk** packages for feature extraction."
   ],
   "id": "e0a5fca79bcca55f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e1204f7b398b8a19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5db4e6e475359f1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "17ef8f88417cbbdf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5: Clustering\n",
    "\n",
    "**Objective**: Cluster news articles based on their content.\n",
    "\n",
    "1. Apply KMeans clustering to group news articles into 42 clusters.\n",
    "2. Visualize the clusters using PCA or t-SNE."
   ],
   "id": "e4c0485d1397a8c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "618184bbf1586562"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f9d62f80e0fcbae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f09fe8151939a692"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 6: Model Training\n",
    "\n",
    "**Objective**: Train machine learning models for text classification.\n",
    "\n",
    "1. Train various machine learning models on the preprocessed and vectorized data.\n",
    "   - Choose models from the **sklearn** library (e.g., Logistic Regression, Random Forest, SVM).\n",
    "   "
   ],
   "id": "c384b0a5acc0b062"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a26c181298845ca4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de89bd92eb9e729f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d48b0da7d9b1a4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 7: Model Evaluation\n",
    "\n",
    "**Objective**: Evaluate the performance of the trained models.\n",
    "\n",
    "1. Evaluate the models using appropriate metrics such as accuracy, precision, recall, and F1-score.\n",
    "2. Perform **cross-validation** on at least one model to ensure reliable performance evaluation.\n"
   ],
   "id": "67d1c24939321e06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55c8fdbf9aace97e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc93d4f22fedbe00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9088fc738117a2b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
