{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Extract data using Google **Places API***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Google Places API** is a programming interface that allows you to access detailed information about places around the world, such as businness, points of interest and venues, including data such as names, addresses, ratings, reviews and geographic coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librarys\n",
    "Here we import the librarys we need to extract our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from transformers.utils import logging\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "viana_axis_hotel = 'AXIS VIANA BUSINESS & SPA HOTEL'\n",
    "ponte_lima_axis_hotel = 'Axis Ponte de Lima Golf Resort Hotel'\n",
    "ofir_axis_hotel = 'Axis Ofir Beach Resort Hotel'\n",
    "braga_axis_hotel = 'Basic Braga by Axis'\n",
    "vermar_axis_hotel = 'Hotel Axis Vermar Conference & Beach Hotel'\n",
    "porto_axis_hotel = 'Axis Porto Business & SPA Hotel'\n",
    "porto_club_axis_hotel = 'Axis Porto Club Hotel'\n",
    "\n",
    "\n",
    "def get_hotel_reviews(hotel_name, api_key):\n",
    "    import googlemaps\n",
    "    \"\"\"Fetches all reviews for a hotel using the Google Places API, handling pagination.\"\"\"\n",
    "    gmaps = googlemaps.Client(key=api_key)\n",
    "\n",
    "    place_id = gmaps.find_place(\n",
    "        input=hotel_name,\n",
    "        input_type='textquery',\n",
    "        fields=['place_id']\n",
    "    )['candidates'][0]['place_id']\n",
    "\n",
    "    all_reviews = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        place_details = gmaps.place(\n",
    "            place_id,\n",
    "            fields=['name', 'reviews']\n",
    "        )\n",
    "\n",
    "        reviews = place_details['result']['reviews']\n",
    "\n",
    "        for review in reviews:\n",
    "            all_reviews.append({\n",
    "                'review_text': review.get('text', ''),\n",
    "                'rating': review.get('rating', None)\n",
    "            })\n",
    "\n",
    "        if 'next_page_token' in place_details['result']:\n",
    "            next_page_token = place_details['result']['next_page_token']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "\n",
    "def save_reviews_to_csv(reviews, file_name):\n",
    "    \"\"\"Saves hotel reviews to a CSV file.\"\"\"\n",
    "    with open(file_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Review', 'Classification'])\n",
    "        for review in reviews:\n",
    "            writer.writerow([review.get('review_text', ''), review.get('rating', '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"MAPS_API_KEY\")\n",
    "\n",
    "viana_reviews = get_hotel_reviews(viana_axis_hotel, API_KEY)\n",
    "save_reviews_to_csv(viana_reviews, 'viana_reviews.csv')\n",
    "\n",
    "ponte_lima_reviews = get_hotel_reviews(ponte_lima_axis_hotel, API_KEY)\n",
    "save_reviews_to_csv(ponte_lima_reviews, 'ponte_lima_reviews.csv')\n",
    "\n",
    "ofir_reviews = get_hotel_reviews(ofir_axis_hotel, API_KEY)\n",
    "save_reviews_to_csv(ofir_reviews, 'ofir_reviews.csv')\n",
    "\n",
    "braga_reviews = get_hotel_reviews(braga_axis_hotel, API_KEY)\n",
    "save_reviews_to_csv(braga_reviews, 'braga_reviews.csv')\n",
    "\n",
    "vermar_reviews = get_hotel_reviews(vermar_axis_hotel, API_KEY)\n",
    "save_reviews_to_csv(vermar_reviews, 'vermar_reviews.csv')\n",
    "\n",
    "porto_business_reviews = get_hotel_reviews(porto_axis_hotel, API_KEY)\n",
    "save_reviews_to_csv(porto_business_reviews, 'porto_business_reviews.csv')\n",
    "\n",
    "porto_club_reviews = get_hotel_reviews(porto_club_axis_hotel, API_KEY)\n",
    "save_reviews_to_csv(porto_club_reviews, 'porto_club_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code aims to extract hotel reviews and ratings and save the data to a CSV file.\n",
    "\n",
    "In the first part, the `get_hotel_reviews` function is reponsible for fetching the reviews. It takes the hotel name as input and finds the associated location ID. It then collects all available reviews, including the review text and rating. The code also handles automatic pagination to ensure that all reviews are captured (for free use, the API only provides 5 reviews per location).\n",
    "\n",
    "In the second part, the `save_reviews_to_csv` function organises this data and saves it to a CSV file. The final table contains two columns: one for the text of the reviews (*Review*) and another for the numerical classifications (*Classification*).\n",
    "\n",
    "With this process, the date is cleanly structured and can be analysed later in **Power BI**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['viana_reviews.csv', 'ponte_lima_reviews.csv', 'ofir_reviews.csv', \n",
    "              'braga_reviews.csv', 'vermar_reviews.csv', 'porto_business_reviews.csv', 'porto_club_reviews.csv']\n",
    "\n",
    "combined_df = pd.read_csv(file_paths[0])\n",
    "\n",
    "for file_path in file_paths[1:]:\n",
    "    temp_df = pd.read_csv(file_path, header=0) \n",
    "    combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "\n",
    "output_path = 'combined.csv'\n",
    "with open(output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(combined_df.columns)\n",
    "    writer.writerows(combined_df.values)\n",
    "\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code combines several databases stored in CSV files into a single consolidated file called `combined.csv`, removing the original files at the end of the process.\n",
    "\n",
    "First, it creates a list of paths from the individual files, each containing reviews of different hotels. The script reads the first file in the list and stores its contents in a *Pandas DataFrame*, which is an efficient data structure for manipulating tables. Then, for each subsequent file, it loads the data into a temporary *DataFrame* and concatenates (joins) this data to the main *DataFrame*, ensuring that all the information is consistent.\n",
    "\n",
    "Once the data from all the files has been combined, the code writes the consolidated content to a new CSV file called `combined.csv`, preserving the original columns and their respective rows. To do this, it uses the *csv* library and writes both the column names and the data in tabular format.\n",
    "\n",
    "Finally, the script checks for the existence of the individual input files and deletes them, leaving only the combined file. The result is a single file containing all the hotel reviews, making it easier to analyse them later without having to deal with several separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_stop_words(text: str):\n",
    "    # Ensure required NLTK resources are downloaded\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    # Initialize stop sword set and stemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs \n",
    "    text = re.sub(r'\\W', ' ', text) # Remove non-alphanumeric characters (punctuation, special symbols, etc)\n",
    "    text = re.sub(r'\\d+', '', text) # Remove numeric values\n",
    "    tokenize = word_tokenize(text) \n",
    "    words = [word for word in tokenize if word not in stop_words] # Remove stop words\n",
    "\n",
    "    # Join the processed words back into a single string with spaces\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `removing_stop_words` takes a string as input and performs several text cleaning steps. It first ensures the required NLTK resources for tokenization and stop words are downloaded. Then, it checks if the input is a string; if not, it returns an empty string.\n",
    "\n",
    "The function proceeds by removing URLs, non-alphanumeric characters, and numeric values using regular expressions. It then tokenizes the cleaned text into individual words and filters out stop words (common, less meaningful words) using the NLTK stop word list.\n",
    "\n",
    "Finally, the function joins the remaining words back into a single string and returns it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diogo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "file_path = 'combined.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "if 'Review' in df.columns:\n",
    "    # Adding a new column with the original reviews\n",
    "    df['Original_Review'] = df['Review']\n",
    "    # Apply the preprocessing function in the data\n",
    "    df['Review'] = df['Review'].apply(removing_stop_words)\n",
    "\n",
    "    # Saving the result in a new csv file\n",
    "    processed_file_path = 'Processed_Project.csv'\n",
    "    with open(processed_file_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(df.columns) # Writing the headers\n",
    "        writer.writerows(df.values) # Writing the DataFrame lines\n",
    "\n",
    "os.remove(file_path) # Removing the original file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code processes a CSV file containing reviews, applying a text preprocessing function to clean the *Review* column. First, it reads the data from a file called `combined.csv` into a pandas DataFrame. It then checks if the *Review* column exists in the DataFrame. If it does, the code creates a new column, *Original_Review*, to store the original review content. Next, the function `removing_stop_words` is applied to each review, removing stop words, special characters, numbers, and URLs.\n",
    "\n",
    "After preprocessing the reviews, the updated DataFrame is saved to a new file, `Processed_Project.csv`. The code writes both the column headers and the processed review data to the new file. Finally, it deletes the original CSV file (`combined.csv`) to leave only the processed version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()\n",
    "\n",
    "file_path = 'Processed_Project.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "review_column = 'Review'\n",
    "\n",
    "def analyze_sentiment(text: str):\n",
    "    \"\"\"\n",
    "    Performs sentiment analysis on a given text using a pre-trained model from Hugging Face Transformers.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be analyzed\n",
    "\n",
    "    Returns:\n",
    "        str: The sentiment label predicted by the model ('POSITIVE' or 'NEGATIVE').env\n",
    "            Returns 'No analysis' if the input is invalid or null.\n",
    "    \"\"\"\n",
    "    from transformers import pipeline\n",
    "\n",
    "    # Initialize the sentiment-analysis pipeline\n",
    "    # The pipeline uses a pre-trained model to classify sentiment (e.g., POSITIVE or NEGATIVE)\n",
    "    sentiment_pipeline = pipeline(task='sentiment-analysis', device=\"cuda\")\n",
    "\n",
    "    # Check if the input is a valid, no-null string\n",
    "    if isinstance(text, str) and pd.notnull(text): \n",
    "        # If the input is valid, call the sentiment-analysis pipeline\n",
    "        # The pipeline returns a list of dictionares; [0] accesses the first result, and ['label'] gets the sentiment label\n",
    "        return sentiment_pipeline(text)[0]['label'] \n",
    "    else:\n",
    "         # If the input is invalid (not a string or null), return \"No analysis\"\n",
    "        return \"No analysis\"\n",
    "\n",
    "df['Sentiment'] = df[review_column].apply(analyze_sentiment)\n",
    "sentiment_map = {'POSITIVE': 1, 'NEGATIVE': 0}\n",
    "df['Binary_Sentiment'] = df['Sentiment'].map(sentiment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code processes reviews from a CSV file by performing sentiment analysis on the text using a pre-trained model from *Hugging Face’s Transformers* library. It defines a function called `analyze_sentiment` that classifies each review as either *POSITIVE* or *NEGATIVE* based on the model’s prediction. This function is applied to the *Review* column of the DataFrame, and the sentiment results are stored in a new column called *Sentiment*.\n",
    "\n",
    "Additionally, the code converts the sentiment labels into binary values, mapping *POSITIVE* to 1 and *NEGATIVE* to 0. These binary values are saved in a new column, *Binary_Sentiment*. The overall goal of the code is to categorize the sentiment of the review texts for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results in a new CSV file\n",
    "output_path = 'Sentiment_analysis.csv'\n",
    "\n",
    "with open(output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(df.columns)\n",
    "    writer.writerows(df.values)\n",
    "\n",
    "# Deleting the original file\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python code saves the processed DataFrame, which contains the sentiment analysis results, into a new CSV file (`Sentiment_analysis.csv`). It opens the file in write mode and uses the csv.writer to write the column headers and the data from the DataFrame into the new file.\n",
    "\n",
    "After saving the results, the code checks if the original file (file_path) exists. If it does, the file is deleted using os.remove(file_path), ensuring that only the new file with the sentiment analysis results remains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dashboard.png\" width=\"20%\" align=\"center\"/>\n",
    "\n",
    "dsdssd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tac-hands-on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
